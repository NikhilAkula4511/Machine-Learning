{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3226425c-13e8-425f-922a-13d7d2a4e568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:08:23 INFO mlflow.tracking.fluent: Experiment with name 'Sentiment Analysis Using MLOPS ' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/Hello/Desktop/MLOPS/mlruns/609289338975354017', creation_time=1711640303226, experiment_id='609289338975354017', last_update_time=1711640303226, lifecycle_stage='active', name='Sentiment Analysis Using MLOPS ', tags={}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"Sentiment Analysis Using MLOPS \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15091361-e98c-4946-88dd-fdd65be9193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb42974a-2879-49de-a336-29b397ad928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Hello\\INTERNSHIP\\reviews_badminton\\data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8930e4d7-a51c-4c57-9e0a-9c7056d1b46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Reviewer Name               Review Title  \\\n",
       "0               Kamal Suresh               Nice product   \n",
       "1          Flipkart Customer     Don't waste your money   \n",
       "2     A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3        Suresh Narayanasamy                       Fair   \n",
       "4                  ASHIK P A                Over priced   \n",
       "...                      ...                        ...   \n",
       "8513                     NaN                        NaN   \n",
       "8514                     NaN                        NaN   \n",
       "8515                     NaN                        NaN   \n",
       "8516                     NaN                        NaN   \n",
       "8517                     NaN                        NaN   \n",
       "\n",
       "                  Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0      Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1      Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2     Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3        Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                             NaN     147.0        24.0  Apr 2016   \n",
       "...                           ...       ...         ...       ...   \n",
       "8513                          NaN       NaN         NaN       NaN   \n",
       "8514                          NaN       NaN         NaN       NaN   \n",
       "8515                          NaN       NaN         NaN       NaN   \n",
       "8516                          NaN       NaN         NaN       NaN   \n",
       "8517                          NaN       NaN         NaN       NaN   \n",
       "\n",
       "                                            Review text  Ratings  \n",
       "0     Nice product, good quality, but price is now r...        4  \n",
       "1     They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2     Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3     Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4     Over pricedJust â?¹620 ..from retailer.I didn'...        1  \n",
       "...                                                 ...      ...  \n",
       "8513                                                NaN        5  \n",
       "8514                                                NaN        2  \n",
       "8515                                                NaN        4  \n",
       "8516                                                NaN        1  \n",
       "8517                                                NaN        4  \n",
       "\n",
       "[8518 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfa4ebc8-e0bf-4e7a-93fc-e831799573e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8518 entries, 0 to 8517\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8508 non-null   object \n",
      " 1   Review Title     8508 non-null   object \n",
      " 2   Place of Review  8468 non-null   object \n",
      " 3   Up Votes         8508 non-null   float64\n",
      " 4   Down Votes       8508 non-null   float64\n",
      " 5   Month            8053 non-null   object \n",
      " 6   Review text      8510 non-null   object \n",
      " 7   Ratings          8518 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 532.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae7c2558-60b7-4590-9acc-de559186abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2= df[['Ratings','Review text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7614ffcc-6e52-4d80-ab0d-91bfdf565545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ratings        0\n",
       "Review text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = df_2.dropna()\n",
    "df_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f253e1c9-cb8e-45b9-9d9d-09f2001a28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['Ratings'] = df_2['Ratings'].apply(lambda x: 'Negative' if x < 3 else ('Neutral' if x == 3 else 'Positive'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c7155be-ba6c-4ace-92ed-63b1b8b2776d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8505</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Delivered before time but price is high from m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8506</th>\n",
       "      <td>Positive</td>\n",
       "      <td>up to the mark but same is available in market...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8507</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Nice delivery speedREAD MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8508</th>\n",
       "      <td>Positive</td>\n",
       "      <td>No complaints about the item . Its the best on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Not sure why we have charged for this product ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8510 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ratings                                        Review text\n",
       "0     Positive  Nice product, good quality, but price is now r...\n",
       "1     Negative  They didn't supplied Yonex Mavis 350. Outside ...\n",
       "2     Negative  Worst product. Damaged shuttlecocks packed in ...\n",
       "3      Neutral  Quite O. K. , but nowadays  the quality of the...\n",
       "4     Negative  Over pricedJust â?¹620 ..from retailer.I didn'...\n",
       "...        ...                                                ...\n",
       "8505   Neutral  Delivered before time but price is high from m...\n",
       "8506  Positive  up to the mark but same is available in market...\n",
       "8507  Positive                       Nice delivery speedREAD MORE\n",
       "8508  Positive  No complaints about the item . Its the best on...\n",
       "8509  Negative  Not sure why we have charged for this product ...\n",
       "\n",
       "[8510 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18fecf72-16db-49cb-9e8a-12261a283c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Preprocessing on train data (X_train)\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76664d7a-08b8-480b-883e-ae835481c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc): # doc is a string of text\n",
    "    doc = doc.replace(\"READ MORE\", \"\")\n",
    "    \n",
    "    # Remove punctuation and numbers.\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "\n",
    "    # Converting to lower case\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in lemmatized_tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join and return\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6af44c4-cf73-4cb0-9e8e-e88f9f74d730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5957, 1), (2553,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_2.pop('Ratings')\n",
    "X=df_2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=45)\n",
    "X_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1df57b2f-c716-4fb0-bd65-e73388c11f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5957/5957 [00:03<00:00, 1690.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.44 s\n",
      "Wall time: 3.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5957,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improving the efficiency by applying cleaning the text data before hand\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas()\n",
    "%time X_train_clean = X_train['Review text'].progress_apply(lambda text: clean(text))\n",
    "\n",
    "X_train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76ad2de0-cfc6-46dd-8616-25597558add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2553/2553 [00:01<00:00, 1632.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.48 s\n",
      "Wall time: 1.57 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2553,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X_test_clean = X_test['Review text'].progress_apply(lambda text: clean(text))\n",
    "\n",
    "X_test_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5e63edb-6cca-4685-a22e-6cf991cb3bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for DecisionTree: 0.8515471993732864\n",
      "Accuracy for Logistic: 0.8629063846455151\n",
      "Accuracy for SVM: 0.8609479044261653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# Assuming X_train and y_train are your training data\n",
    "# Assuming X_test and y_test are your test data\n",
    "\n",
    "# Define pipelines with the best parameters\n",
    "pipelines = {\n",
    "    'DecisionTree': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', DecisionTreeClassifier(max_depth=10, min_samples_split=2))\n",
    "    ]),\n",
    "    'Logistic': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', LogisticRegression(C=1, penalty='l2'))\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', SVC(C=1, kernel='rbf'))\n",
    "    ]),\n",
    "    # Add pipelines for other algorithms with their best parameters\n",
    "}\n",
    "\n",
    "# Fit the pipelines with training data\n",
    "for algo_name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train_clean, y_train)\n",
    "\n",
    "# Evaluate model on test data\n",
    "for algo_name, pipeline in pipelines.items():\n",
    "    y_pred = pipeline.predict(X_test_clean)\n",
    "    accuracy = f1_score(y_test, y_pred,average='micro')\n",
    "    print(f\"Accuracy for {algo_name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcff46ce-35fd-42f9-914c-5d761b1d07de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['Positive' 'Negative' 'Neutral']\n"
     ]
    }
   ],
   "source": [
    "new_data = [\n",
    "    \"Good to \",\"Bad to buy\",\"avg product\"\n",
    "]\n",
    "\n",
    "new_data_clean = [clean(doc) for doc in new_data]\n",
    "\n",
    "prediction = pipeline.predict(new_data_clean)\n",
    "\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dc31cf8-4a6f-49a6-ba36-54df5e0f9e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:28:51 INFO mlflow.tracking.fluent: Experiment with name 'flipkart-sentiment-analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/Hello/Desktop/MLOPS/mlruns/757650632124654277', creation_time=1711641531828, experiment_id='757650632124654277', last_update_time=1711641531828, lifecycle_stage='active', name='flipkart-sentiment-analysis', tags={}>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import time\n",
    "from joblib import Memory\n",
    "import os\n",
    "import mlflow\n",
    "# Define a memory object to cache intermediate results\n",
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "    \n",
    "    'random_forest': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ], memory=memory),\n",
    "    \n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    \n",
    "    'svm': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ], memory=memory),\n",
    "\n",
    "    'knn': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ], memory=memory)\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000], \n",
    "            'classifier__alpha' : [0.1, 0.5, 1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'random_forest': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000],\n",
    "            'classifier__max_depth': [None, 5, 10],\n",
    "            'classifier__n_estimators': [100, 200, 300]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 2000], \n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l1', 'l2'], \n",
    "            'classifier__solver': ['liblinear', 'saga'],\n",
    "        }\n",
    "    ],\n",
    "    'knn': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000], \n",
    "            'classifier__n_neighbors': [3, 5, 7],\n",
    "            'classifier__p': [1, 2]\n",
    "        }\n",
    "    ],\n",
    "    'svm': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000], \n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__gamma': ['scale', 'auto']\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "mlflow.set_experiment('flipkart-sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "013a1bbc-11ca-45bf-8c43-c7eb8029a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:30:52 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "CPU times: total: 14.8 s\n",
      "Wall time: 28.3 s\n",
      "Train Score:  0.8623459937446255\n",
      "Test Score:  0.864081472777125\n",
      "\n",
      "********** random_forest **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:31:20 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "CPU times: total: 7min 10s\n",
      "Wall time: 7min 34s\n",
      "Train Score:  0.8541202354347773\n",
      "Test Score:  0.854289071680376\n",
      "\n",
      "********** logistic_regression **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:38:56 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "CPU times: total: 1min 41s\n",
      "Wall time: 1min 55s\n",
      "Train Score:  0.8616749657341103\n",
      "Test Score:  0.8597728162945554\n",
      "\n",
      "********** svm **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:40:52 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "CPU times: total: 2min 48s\n",
      "Wall time: 3min 5s\n",
      "Train Score:  0.8568058694657735\n",
      "Test Score:  0.8558558558558559\n",
      "\n",
      "********** knn **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:43:59 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "CPU times: total: 2min 9s\n",
      "Wall time: 1min 22s\n",
      "Train Score:  0.8499237737208317\n",
      "Test Score:  0.8511555033294164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for each algorithm and log in the mlflow\n",
    "dev = 'Akula Nikhil'\n",
    "best_models = {}\n",
    "\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    clf = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=3, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "\n",
    "    #autologging\n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time clf.fit(X_train_clean, y_train)\n",
    "        \n",
    "    print('Train Score: ', clf.best_score_)\n",
    "    print('Test Score: ', clf.score(X_test_clean, y_test))\n",
    "\n",
    "    best_models[algo] = clf.best_estimator_\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f86a1-1473-4904-8801-832f557a2dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f220b-9abb-49aa-a73e-aae560d99318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac120185-15d0-4103-83c2-bfad2f7df38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718c892-9d21-4555-b7b9-ec21954f880c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76efb6ac-6c57-4a8b-b1cf-f006a0534d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8eb26-5c6f-4e26-880f-49c1300f352a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
